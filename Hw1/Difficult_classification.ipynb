{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mp1 import generate_dataset_classification\n",
    "from mp1 import generate_test_set_classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "from pandas import get_dummies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data:\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "Creating data:\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "[x_train, t_train] = generate_dataset_classification(300, 20, True)\n",
    "t_train = get_dummies(t_train).values\n",
    "\n",
    "[x_test, t_test] = generate_test_set_classification()\n",
    "t_test = get_dummies(t_test).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with 1-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/80\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 1.3468 - acc: 0.2767\n",
      "Epoch 2/80\n",
      "300/300 [==============================] - 0s 284us/step - loss: 1.1716 - acc: 0.3033\n",
      "Epoch 3/80\n",
      "300/300 [==============================] - 0s 283us/step - loss: 1.0901 - acc: 0.4067\n",
      "Epoch 4/80\n",
      "300/300 [==============================] - 0s 293us/step - loss: 1.0558 - acc: 0.4200\n",
      "Epoch 5/80\n",
      "300/300 [==============================] - 0s 294us/step - loss: 1.0011 - acc: 0.5067\n",
      "Epoch 6/80\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.9953 - acc: 0.5533\n",
      "Epoch 7/80\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.9712 - acc: 0.5200\n",
      "Epoch 8/80\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.9378 - acc: 0.5467\n",
      "Epoch 9/80\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.9470 - acc: 0.5500\n",
      "Epoch 10/80\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.9758 - acc: 0.4600\n",
      "Epoch 11/80\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.9103 - acc: 0.5500\n",
      "Epoch 12/80\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.9338 - acc: 0.5467\n",
      "Epoch 13/80\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.8716 - acc: 0.5867\n",
      "Epoch 14/80\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.8814 - acc: 0.5967\n",
      "Epoch 15/80\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.9527 - acc: 0.4967\n",
      "Epoch 16/80\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.8804 - acc: 0.5867\n",
      "Epoch 17/80\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.8658 - acc: 0.6000\n",
      "Epoch 18/80\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.8432 - acc: 0.6033\n",
      "Epoch 19/80\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.8925 - acc: 0.6000\n",
      "Epoch 20/80\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.8918 - acc: 0.5567\n",
      "Epoch 21/80\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.8143 - acc: 0.6433\n",
      "Epoch 22/80\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.8153 - acc: 0.6300\n",
      "Epoch 23/80\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.8271 - acc: 0.5867\n",
      "Epoch 24/80\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.8294 - acc: 0.6300\n",
      "Epoch 25/80\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.8276 - acc: 0.5800\n",
      "Epoch 26/80\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.7981 - acc: 0.6000\n",
      "Epoch 27/80\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.7773 - acc: 0.6500\n",
      "Epoch 28/80\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.7788 - acc: 0.6367\n",
      "Epoch 29/80\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.7786 - acc: 0.6333\n",
      "Epoch 30/80\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.7899 - acc: 0.6333\n",
      "Epoch 31/80\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.7437 - acc: 0.6800\n",
      "Epoch 32/80\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.7466 - acc: 0.6467\n",
      "Epoch 33/80\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.7624 - acc: 0.6167\n",
      "Epoch 34/80\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.7452 - acc: 0.6467\n",
      "Epoch 35/80\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.7538 - acc: 0.6567\n",
      "Epoch 36/80\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.7614 - acc: 0.6367\n",
      "Epoch 37/80\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.7622 - acc: 0.6200\n",
      "Epoch 38/80\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.7315 - acc: 0.6667\n",
      "Epoch 39/80\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.7231 - acc: 0.6700\n",
      "Epoch 40/80\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.7241 - acc: 0.6767\n",
      "Epoch 41/80\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.7159 - acc: 0.6867\n",
      "Epoch 42/80\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.7114 - acc: 0.6867\n",
      "Epoch 43/80\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.7004 - acc: 0.6867\n",
      "Epoch 44/80\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.7471 - acc: 0.6333\n",
      "Epoch 45/80\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.7303 - acc: 0.6467\n",
      "Epoch 46/80\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.6995 - acc: 0.7000\n",
      "Epoch 47/80\n",
      "300/300 [==============================] - 0s 426us/step - loss: 0.7291 - acc: 0.6333\n",
      "Epoch 48/80\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.7050 - acc: 0.6633\n",
      "Epoch 49/80\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.6840 - acc: 0.7000\n",
      "Epoch 50/80\n",
      "300/300 [==============================] - 0s 482us/step - loss: 0.6868 - acc: 0.7067\n",
      "Epoch 51/80\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.6917 - acc: 0.7033\n",
      "Epoch 52/80\n",
      "300/300 [==============================] - 0s 439us/step - loss: 0.7264 - acc: 0.6567\n",
      "Epoch 53/80\n",
      "300/300 [==============================] - 0s 422us/step - loss: 0.6963 - acc: 0.6933\n",
      "Epoch 54/80\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.6888 - acc: 0.6700\n",
      "Epoch 55/80\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.6938 - acc: 0.6767\n",
      "Epoch 56/80\n",
      "300/300 [==============================] - 0s 466us/step - loss: 0.6719 - acc: 0.6867\n",
      "Epoch 57/80\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.6794 - acc: 0.7100\n",
      "Epoch 58/80\n",
      "300/300 [==============================] - 0s 411us/step - loss: 0.6898 - acc: 0.6767\n",
      "Epoch 59/80\n",
      "300/300 [==============================] - 0s 469us/step - loss: 0.6666 - acc: 0.7000\n",
      "Epoch 60/80\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.6936 - acc: 0.6733\n",
      "Epoch 61/80\n",
      "300/300 [==============================] - 0s 386us/step - loss: 0.6850 - acc: 0.6933\n",
      "Epoch 62/80\n",
      "300/300 [==============================] - 0s 442us/step - loss: 0.7067 - acc: 0.6767\n",
      "Epoch 63/80\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.6976 - acc: 0.6567\n",
      "Epoch 64/80\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.7202 - acc: 0.6533\n",
      "Epoch 65/80\n",
      "300/300 [==============================] - 0s 480us/step - loss: 0.7215 - acc: 0.6400\n",
      "Epoch 66/80\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.6921 - acc: 0.6500\n",
      "Epoch 67/80\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.6605 - acc: 0.7133\n",
      "Epoch 68/80\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.6449 - acc: 0.7067\n",
      "Epoch 69/80\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.6450 - acc: 0.7067\n",
      "Epoch 70/80\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.6393 - acc: 0.7200\n",
      "Epoch 71/80\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.6466 - acc: 0.7300\n",
      "Epoch 72/80\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.6439 - acc: 0.7300\n",
      "Epoch 73/80\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.6532 - acc: 0.6967\n",
      "Epoch 74/80\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.6389 - acc: 0.7067\n",
      "Epoch 75/80\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.6352 - acc: 0.7300\n",
      "Epoch 76/80\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.6261 - acc: 0.7167\n",
      "Epoch 77/80\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.6538 - acc: 0.6967\n",
      "Epoch 78/80\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.6254 - acc: 0.7267\n",
      "Epoch 79/80\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.6224 - acc: 0.7167\n",
      "Epoch 80/80\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.6321 - acc: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fda6068c18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = Sequential([\n",
    "        Dense(3, input_dim=10000),\n",
    "        Activation('softmax'),\n",
    "    \n",
    "    #Dense(1000, input_dim=10000),\n",
    "    #Activation('relu'),\n",
    "    #Dense(500),\n",
    "    #Activation('relu'),\n",
    "    #Dense(100),\n",
    "    #Activation('relu'),\n",
    "    #Dense(3),\n",
    "    #Activation('softmax'),\n",
    "])\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "dnn.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "print('Training ------------')\n",
    "dnn.fit(x_train, t_train, epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/40\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0832 - acc: 0.4300\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8832 - acc: 0.6133\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.6734 - acc: 0.7100\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.5500 - acc: 0.7767\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4611 - acc: 0.8233\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3877 - acc: 0.8900\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3374 - acc: 0.9000\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2668 - acc: 0.9500\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2470 - acc: 0.9533\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2186 - acc: 0.9533\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1825 - acc: 0.9567\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1578 - acc: 0.9767\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1406 - acc: 0.9733\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1240 - acc: 0.9800\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1197 - acc: 0.9800\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1043 - acc: 0.9867\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9833\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0863 - acc: 0.9900\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0781 - acc: 0.9900\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0663 - acc: 0.9967\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0678 - acc: 0.9933\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0598 - acc: 0.9967\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0561 - acc: 0.9967\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0500 - acc: 0.9967\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0465 - acc: 0.9967\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0443 - acc: 0.9967\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0405 - acc: 0.9967\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0382 - acc: 0.9967\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0373 - acc: 0.9967\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0376 - acc: 0.9967\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0381 - acc: 0.9967\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0309 - acc: 0.9967\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0298 - acc: 0.9967\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0288 - acc: 0.9967\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0318 - acc: 0.9967\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 37/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0261 - acc: 0.9967\n",
      "Epoch 38/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0228 - acc: 0.9967\n",
      "Epoch 39/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0239 - acc: 0.9967\n",
      "Epoch 40/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0233 - acc: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fda4fca898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential()  \n",
    "cnn.add(Conv2D(filters=16,  \n",
    "               kernel_size=(5,5),  \n",
    "               padding='same',  \n",
    "               input_shape=(100,100,1),  \n",
    "               activation='relu'))  \n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))  \n",
    "cnn.add(Conv2D(filters=36,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=(28,28,1),  \n",
    "                 activation='relu'))  \n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))  \n",
    "cnn.add(Flatten())  \n",
    "cnn.add(Dense(128, activation='relu'))  \n",
    "cnn.add(Dense(3, activation='softmax'))  \n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "print('Training ------------')\n",
    "cnn.fit(np.reshape(x_train, (-1, 100, 100, 1)), t_train, epochs=40, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
